{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca0bb2-f26f-4811-81ec-2619c6d229e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "import napari\n",
    "from skimage import io\n",
    "import nd2reader\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import label\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.io import imsave\n",
    "from skimage.draw import disk\n",
    "import ipywidgets as widgets\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91982fe8-d17b-45b8-9aa3-bac87d251509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = io.imread(r\"C:\\Users\\Sean\\code\\gold_id\\1y1_lrm_single_fov.tif\")\n",
    "\n",
    "# Define the channels and their names\n",
    "channels = {0: 'DAPI', 1: 'FITC', 2: 'TRITC', 3: 'CY5'}\n",
    "\n",
    "# Initialize a dictionary to hold the images for each channel\n",
    "images = {name: image[..., channel] for channel, name in channels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c610f7d-64f2-4c99-960f-470bee8f77b7",
   "metadata": {},
   "source": [
    "# Background processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39c79e-1550-4af7-b0db-d2eebfdcf5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_background_subtraction(image):\n",
    "    background = np.median(image)\n",
    "    return image - background\n",
    "\n",
    "def high_pass_filter(image, sigma=50):\n",
    "    background = gaussian_filter(image, sigma)\n",
    "    return background - image\n",
    "\n",
    "def mog2_background_subtraction(image):\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    return fg_mask - image\n",
    "\n",
    "def otsu_threshold(image):\n",
    "    _, image_subtracted = cv2.threshold(image, 0, 4095, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return image_subtracted\n",
    "\n",
    "def tophat_transform_white(image): \n",
    "    disk_size = morphology.disk(25)\n",
    "    white_tophat = morphology.white_tophat(image, disk_size)\n",
    "    return white_tophat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb924d-2765-467f-9b48-c01320ee3f30",
   "metadata": {},
   "source": [
    "# image whitening \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e21d5-82fe-43e4-8161-edaddfeb1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica_whitening(image):\n",
    "    # Flatten the image\n",
    "    flat_image = image.flatten()\n",
    "\n",
    "    # Reshape the image to 2D (FastICA requires 2D inputs)\n",
    "    reshaped_image = flat_image.reshape(-1, 1)\n",
    "    \n",
    "    # Apply FastICA\n",
    "    ica = FastICA()\n",
    "    whitened_image = ica.fit_transform(reshaped_image)\n",
    "\n",
    "    # Reshape the whitened image back to the original shape\n",
    "    whitened_image = whitened_image.reshape(image.shape)\n",
    "\n",
    "    return whitened_image\n",
    "\n",
    "def zca_whitening(image):\n",
    "    # Convert the image to float type for more precise calculations\n",
    "    image = image.astype(float)\n",
    "\n",
    "    # Calculate the mean of the image\n",
    "    mean = image.mean()\n",
    "\n",
    "    # Subtract the mean from the image. This centers the image around 0\n",
    "    image -= mean\n",
    "\n",
    "    # Calculate the covariance matrix of the image\n",
    "    sigma = np.dot(image.T, image) / image.size\n",
    "\n",
    "    # Perform Singular Value Decomposition (SVD) on the covariance matrix\n",
    "    # U contains the left singular vectors, S contains the singular values, and V contains the right singular vectors\n",
    "    U, S, V = np.linalg.svd(sigma)\n",
    "\n",
    "    # A small constant for numerical stability\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    # Calculate the ZCA whitening matrix. This matrix, when applied to the image, will reduce the redundancy in the image's pixels\n",
    "    ZCAMatrix = np.dot(np.dot(U, np.diag(1.0 / np.sqrt(S + epsilon))), U.T)\n",
    "\n",
    "    # Apply the ZCA whitening matrix to the image and add the mean back to the result\n",
    "    return np.dot(image, ZCAMatrix) + mean\n",
    "\n",
    "def pca_whitening(image):\n",
    "    # Convert the image to float\n",
    "    image = image.astype(float)\n",
    "\n",
    "    # Calculate the covariance matrix\n",
    "    cov = np.cov(image)\n",
    "\n",
    "    # Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "    # Sort the eigenvalues and corresponding eigenvectors\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:,idx]\n",
    "\n",
    "    # Compute the inverse square root of the eigenvalues\n",
    "    sqrt_eigenvalues = np.sqrt(eigenvalues + 1e-5)\n",
    "\n",
    "    # Compute the whitened image\n",
    "    whitened_image = np.dot(eigenvectors, np.dot(np.diag(1.0/sqrt_eigenvalues), np.dot(eigenvectors.T, image)))\n",
    "\n",
    "    # Scale the whitened image back to the range [0, 4095]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 4095))\n",
    "    scaled_image = scaler.fit_transform(whitened_image)\n",
    "\n",
    "    return scaled_image\n",
    "\n",
    "# Gaussian blur\n",
    "def blur(image):\n",
    "    # Ensure kernel size is odd\n",
    "    kernel_size=9\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "        \n",
    "    # Calculate the local mean of the image\n",
    "    blurimg = cv2.blur(image, (int(kernel_size), int(kernel_size)))\n",
    "    return blurimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f879611-c365-433c-82a6-d9dc70c742de",
   "metadata": {},
   "source": [
    "## Selecting Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93cf95-159e-4c08-b5a8-8983941f675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the available preprocessing and background subtraction steps\n",
    "preprocessing_steps = {\n",
    "    'No Processing': lambda x: x,\n",
    "    'ICA Whitening': ica_whitening,\n",
    "    'ZCA Whitening': zca_whitening,\n",
    "    'PCA Whitening': pca_whitening,\n",
    "    'Gaussian Blur': blur\n",
    "}\n",
    "\n",
    "background_subtraction_steps = {\n",
    "    'No Processing': lambda x: x,\n",
    "    'Simple Background Subtraction': simple_background_subtraction,\n",
    "    'High Pass Filter': high_pass_filter,\n",
    "    'MOG2 Background Subtraction': mog2_background_subtraction,\n",
    "    'Otsu Threshold': otsu_threshold,\n",
    "    'Tophat Transform White': tophat_transform_white\n",
    "}\n",
    "\n",
    "# Create checkboxes for the user to select the preprocessing steps\n",
    "checkboxes_preprocessing = widgets.SelectMultiple(\n",
    "    options=preprocessing_steps.keys(),\n",
    "    description='Preprocessing:',\n",
    ")\n",
    "\n",
    "# Create checkboxes for the user to select the background subtraction steps\n",
    "checkboxes_background_subtraction = widgets.SelectMultiple(\n",
    "    options=background_subtraction_steps.keys(),\n",
    "    description='Background Subtraction:',\n",
    ")\n",
    "\n",
    "# Create a dropdown menu for the user to select the order of the steps\n",
    "dropdown_order = widgets.Dropdown(\n",
    "    options=['Preprocessing first', 'Background subtraction first'],\n",
    "    value='Preprocessing first',\n",
    "    description='Order:',\n",
    ")\n",
    "\n",
    "# Initialize the processed_images dictionary\n",
    "processed_images = {}\n",
    "\n",
    "# Define a function to apply the selected preprocessing and background subtraction steps\n",
    "def apply_preprocessing_steps(b):\n",
    "    selected_preprocessing_steps = checkboxes_preprocessing.value\n",
    "    selected_background_subtraction_steps = checkboxes_background_subtraction.value\n",
    "    order = dropdown_order.value\n",
    "    for channel in ['DAPI', 'CY5']:\n",
    "        processed_image = images[channel]\n",
    "        # Apply the selected preprocessing and background subtraction steps in the selected order\n",
    "        if order == 'Preprocessing first':\n",
    "            for step in selected_preprocessing_steps:\n",
    "                processed_image = preprocessing_steps[step](processed_image)\n",
    "            for step in selected_background_subtraction_steps:\n",
    "                processed_image = background_subtraction_steps[step](processed_image)\n",
    "        else:\n",
    "            for step in selected_background_subtraction_steps:\n",
    "                processed_image = background_subtraction_steps[step](processed_image)\n",
    "            for step in selected_preprocessing_steps:\n",
    "                processed_image = preprocessing_steps[step](processed_image)\n",
    "        \n",
    "        # Store the processed image in the dictionary\n",
    "        processed_images[channel + ' ' + ' + '.join(selected_preprocessing_steps) + ' + ' + ' + '.join(selected_background_subtraction_steps)] = processed_image\n",
    "\n",
    "# Create a button that the user can click to start the processing\n",
    "button_process = widgets.Button(description='Start Processing')\n",
    "button_process.on_click(apply_preprocessing_steps)\n",
    "\n",
    "# Define a function to save the processed images\n",
    "def save_processed_images(b):\n",
    "    # Create a directory to save the processed images\n",
    "    os.makedirs('processed_images', exist_ok=True)\n",
    "    \n",
    "    # Save each processed image\n",
    "    for name, image in processed_images.items():\n",
    "        cv2.imwrite(f'processed_images/{name}.tif', image)\n",
    "\n",
    "# Create a button that the user can click to save the processed images\n",
    "button_save = widgets.Button(description='Save Images')\n",
    "button_save.on_click(save_processed_images)\n",
    "\n",
    "# Define a function to display the processed images\n",
    "def display_processed_images(b):\n",
    "    for channel in ['DAPI', 'CY5']:\n",
    "        processed_image = processed_images[channel + ' ' + ' + '.join(checkboxes_preprocessing.value) + ' + ' + ' + '.join(checkboxes_background_subtraction.value)]\n",
    "        # Display the original and processed images\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axs[0].imshow(images[channel], cmap='gray')\n",
    "        axs[0].set_title(f'Original {channel} Image')\n",
    "        axs[1].imshow(processed_image, cmap='gray')\n",
    "        axs[1].set_title(f'First Step Processed {channel} Image')\n",
    "        axs[2].imshow(processed_image, cmap='gray')\n",
    "        axs[2].set_title(f'Second Step Processed {channel} Image')\n",
    "        plt.show()\n",
    "\n",
    "# Create a button that the user can click to display the processed images\n",
    "button_display = widgets.Button(description='Display Images')\n",
    "button_display.on_click(display_processed_images)\n",
    "\n",
    "# Display the widgets\n",
    "display(checkboxes_preprocessing, checkboxes_background_subtraction, dropdown_order, button_process, button_save, button_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b019a20-ffaa-40c6-97d2-24a3d091296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_images.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d3062-b4c3-405c-a6bb-e9db5b4ed7b2",
   "metadata": {},
   "source": [
    "# isolation forest and anomaly  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887805d7-4e63-4e5a-a4e8-2101f523b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the sub-images\n",
    "sub_image_size = 16\n",
    "\n",
    "sub_images = {channel: [] for channel in ['DAPI', 'CY5']}\n",
    "\n",
    "for channel in ['DAPI', 'CY5']:\n",
    "    key = channel + ' ' + ' + '.join(checkboxes_preprocessing.value) + ' + ' + ' + '.join(checkboxes_background_subtraction.value)\n",
    "    if key in processed_images:\n",
    "        image = processed_images[key]\n",
    "        # Calculate the number of sub-images in each dimension\n",
    "        num_sub_images_x = image.shape[1] // sub_image_size\n",
    "        num_sub_images_y = image.shape[0] // sub_image_size\n",
    "\n",
    "    # Split the image into sub-images\n",
    "    for i in range(num_sub_images_y):\n",
    "        for j in range(num_sub_images_x):\n",
    "            sub_image = image[i*sub_image_size:(i+1)*sub_image_size, j*sub_image_size:(j+1)*sub_image_size]\n",
    "            sub_images[channel].append(sub_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e0d12-f432-4b2b-810f-7c74912df448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the models for each channel\n",
    "models = {}\n",
    "\n",
    "# List of channels to train on\n",
    "train_channels = ['DAPI', 'CY5']\n",
    "\n",
    "for channel in train_channels:\n",
    "    # Get the sub-images for the current channel\n",
    "    sub_images_channel = sub_images[channel]\n",
    "    \n",
    "    # Flatten the sub-images for each channel\n",
    "    flattened_sub_images = [sub_image.flatten() for sub_image in sub_images_channel]\n",
    "\n",
    "    # Train an Isolation Forest model on the flattened sub-images\n",
    "    model=IsolationForest(n_estimators=50, max_samples='auto', contamination=0.5,max_features=1.0)\n",
    "    model.fit(flattened_sub_images)\n",
    "\n",
    "    # Store the model in the dictionary\n",
    "    models[channel] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efc1a1-5075-4060-bc70-6de97c51bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function will assign a value of either 1 or -1 to each sample in the data set \n",
    "#A value of 1 indicates that a point is a normal point while a value of -1 indicates that it is an anomaly.\n",
    "\n",
    "# Predict the anomaly scores\n",
    "# Get the model for the 'DAPI' channel\n",
    "model_dapi = models['DAPI']\n",
    "\n",
    "# Get the model for the 'CY5' channel\n",
    "model_cy5 = models['CY5']\n",
    "\n",
    "# Make predictions on the 'DAPI' channel\n",
    "predictions_dapi = model_dapi.predict(flattened_sub_images)\n",
    "\n",
    "# Make predictions on the 'CY5' channel\n",
    "predictions_cy5 = model_cy5.predict(flattened_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662eb267-46d2-402c-ae03-706e53d0ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting  the prediction scores \n",
    "\n",
    "# Convert the flattened sub-images back to 2D for each channel\n",
    "sub_images_2d_dapi = [sub_image.reshape(sub_image_size, sub_image_size) for sub_image in sub_images['DAPI']]\n",
    "sub_images_2d_cy5 = [sub_image.reshape(sub_image_size, sub_image_size) for sub_image in sub_images['CY5']]\n",
    "\n",
    "# Calculate the sum of each 2D sub-image for each channel\n",
    "sums_dapi = [np.sum(sub_image) for sub_image in sub_images_2d_dapi]\n",
    "sums_cy5 = [np.sum(sub_image) for sub_image in sub_images_2d_cy5]\n",
    "\n",
    "# Create a scatter plot of the sum of each sub-image vs. the prediction score for the 'DAPI' channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(sums_dapi, predictions_dapi, c=predictions_dapi, cmap='RdBu')\n",
    "plt.xlabel('Sum of Sub-Image')\n",
    "plt.ylabel('Prediction Score')\n",
    "plt.title('Predictions for DAPI Channel')\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of the sum of each sub-image vs. the prediction score for the 'CY5' channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(sums_cy5, predictions_cy5, c=predictions_cy5, cmap='RdBu')\n",
    "plt.xlabel('Sum of Sub-Image')\n",
    "plt.ylabel('Prediction Score')\n",
    "plt.title('Predictions for CY5 Channel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dca8ef-ceb6-47b4-bb35-6a04cc062ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the sub images and their prediction scores: \n",
    "\n",
    "# Get the sub-images for each channel that were marked as anomalies\n",
    "anomaly_sub_images = {\n",
    "    'DAPI': [sub_images_2d_dapi[i] for i, prediction in enumerate(predictions_dapi) if prediction == -1],\n",
    "    'CY5': [sub_images_2d_cy5[i] for i, prediction in enumerate(predictions_cy5) if prediction == -1]\n",
    "}\n",
    "\n",
    "# Create a function to display a sub-image\n",
    "def display_sub_image(channel, i):\n",
    "    plt.imshow(anomaly_sub_images[channel][i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown menu to select the channel\n",
    "dropdown = widgets.Dropdown(options=['DAPI', 'CY5'], value='DAPI', description='Channel:')\n",
    "\n",
    "# Create a slider to select the sub-image index\n",
    "slider = widgets.IntSlider(min=0, max=len(anomaly_sub_images[dropdown.value])-1, step=1, value=0)\n",
    "\n",
    "# Update the maximum value of the slider when the dropdown value changes\n",
    "def update_slider(*args):\n",
    "    slider.max = len(anomaly_sub_images[dropdown.value])-1\n",
    "dropdown.observe(update_slider, 'value')\n",
    "\n",
    "# Create interactive widgets to display the sub-images\n",
    "widgets.interact(display_sub_image, channel=dropdown, i=slider)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210a6a0-8898-4d97-b214-a7bccdecbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the anomaly scores for each channel\n",
    "anomaly_scores = {channel: [] for channel in train_channels}  # Use channel names as keys\n",
    "\n",
    "for channel_name, image in images.items():  # Iterate over channel names and images\n",
    "    # Check if the current channel is one of the channels we trained a model on\n",
    "    if channel_name in train_channels:\n",
    "        # Calculate the number of sub-images in each dimension\n",
    "        num_sub_images_x = image.shape[1] // sub_image_size\n",
    "        num_sub_images_y = image.shape[0] // sub_image_size\n",
    "\n",
    "        # Split the image into sub-images and calculate the anomaly score for each sub-image\n",
    "        for i in range(num_sub_images_y):\n",
    "            for j in range(num_sub_images_x):\n",
    "                sub_image = image[i*sub_image_size:(i+1)*sub_image_size, j*sub_image_size:(j+1)*sub_image_size]\n",
    "                anomaly_score = models[channel_name].decision_function([sub_image.flatten()])[0]  # Use channel name as key\n",
    "                anomaly_scores[channel_name].append((i, j, anomaly_score))  # Use channel name as key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a29522-8d64-4f86-8b88-2a6200ccf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the anomaly scores\n",
    "\n",
    "# For each channel\n",
    "for channel, anomaly_scores_channel in anomaly_scores.items():\n",
    "    # Extract the anomaly scores\n",
    "    scores = [score for i, j, score in anomaly_scores_channel]\n",
    "    \n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # Create a histogram of the anomaly scores and get the patches\n",
    "    counts, bins, patches = plt.hist(scores, bins=50)\n",
    "    \n",
    "    # For each patch\n",
    "    for count, patch in zip(counts, patches):\n",
    "        # Get the height and width of the patch\n",
    "        height = patch.get_height()\n",
    "        width = patch.get_width()\n",
    "        \n",
    "        # Calculate the position of the text\n",
    "        x = patch.get_x() + width / 2\n",
    "        y = height\n",
    "        \n",
    "        # Add the text to the plot\n",
    "        plt.text(x, y, str(int(count)), ha='center', va='bottom')\n",
    "    \n",
    "    # Set the title and labels\n",
    "    plt.title(f'Anomaly Scores for {channel} Channel')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45150bd4-05f5-4dad-9a9e-02d946d3c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to display sub-images with anomaly scores less than a threshold\n",
    "def display_anomalies(channel, threshold, index):\n",
    "    # Get the anomaly scores for the selected channel\n",
    "    anomaly_scores_channel = anomaly_scores[channel]\n",
    "\n",
    "    # Filter the sub-images based on the anomaly score threshold\n",
    "    filtered_sub_images = [sub_images[channel][i] for i, (i, j, score) in enumerate(anomaly_scores_channel) if score < threshold]\n",
    "\n",
    "    # Print the count of sub-images\n",
    "    print(f'Number of anomalies: {len(filtered_sub_images)}')\n",
    "\n",
    "    # Display the sub-image at the selected index\n",
    "    if filtered_sub_images:\n",
    "        plt.imshow(filtered_sub_images[index], cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No anomalies found with the current threshold.')\n",
    "\n",
    "# Create a dropdown menu to select the channel\n",
    "dropdown = widgets.Dropdown(options=['DAPI', 'CY5'], value='DAPI', description='Channel:')\n",
    "\n",
    "# Create a slider to select the anomaly score threshold\n",
    "slider_threshold = widgets.FloatSlider(min=-.15, max=-.01, step=0.001, value=0.0, description='Threshold:')\n",
    "\n",
    "# Create a slider to select the index of the sub-image to display\n",
    "slider_index = widgets.IntSlider(min=0, max=100, step=1, value=0, description='Sub Image Index:')  \n",
    "\n",
    "# Create interactive widgets to display the anomalies\n",
    "widgets.interact(display_anomalies, channel=dropdown, threshold=slider_threshold, index=slider_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262c85-65ea-48ca-b0d4-c49b81e3244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the recombined anomaly images for each channel\n",
    "recombined_anomaly_images = {channel: np.zeros_like(images[channel]) for channel in channels.values()}\n",
    "\n",
    "\n",
    "anomaly_thresholds = {channel: 0 for channel in channels.values()}  # Set initial thresholds to 0\n",
    "\n",
    "#You can adjust the detection thresholds by modifying the values in the anomaly_thresholds dictionary. \n",
    "#For example, to increase the threshold for the 'DAPI' channel to -0.1, you can do:\n",
    "\n",
    "anomaly_thresholds['DAPI'] = -0.1\n",
    "anomaly_thresholds['CY5'] = -0.1\n",
    "\n",
    "# Initialize a dictionary to hold the anomaly images for each channel\n",
    "# Convert grayscale images to RGB images\n",
    "anomaly_images = {channel: np.stack([np.copy(images[channel])]*3, axis=-1) for channel in channels.values()}  # Make a copy of the original images\n",
    "# Initialize a dictionary to hold the recombined anomaly images for each channel\n",
    "recombined_anomaly_images = {channel: np.zeros_like(images[channel]) for channel in channels.values()}\n",
    "\n",
    "\n",
    "anomaly_thresholds = {channel: 0 for channel in channels.values()}  # Set initial thresholds to 0\n",
    "\n",
    "anomaly_thresholds['DAPI'] = -0.1 #initial values \n",
    "anomaly_thresholds['CY5'] = -0.2\n",
    "\n",
    "# Create a function to plot images with anomalies based on the thresholds\n",
    "def plot_anomalies(threshold_dapi, threshold_cy5):\n",
    "    # Set the thresholds\n",
    "    anomaly_thresholds['DAPI'] = threshold_dapi\n",
    "    anomaly_thresholds['CY5'] = threshold_cy5\n",
    "\n",
    "    # Initialize a dictionary to hold the anomaly images for each channel\n",
    "    anomaly_images = {channel: np.stack([np.copy(images[channel])]*3, axis=-1) for channel in channels.values()}  # Make a copy of the original images\n",
    "\n",
    "    for channel, anomaly_scores_channel in anomaly_scores.items():\n",
    "        for i, j, anomaly_score in anomaly_scores_channel:\n",
    "            if anomaly_score < anomaly_thresholds[channel]:  # Use the threshold for the current channel\n",
    "                # Draw a circle around the anomaly\n",
    "                rr, cc = circle_perimeter(i*sub_image_size + sub_image_size//2, j*sub_image_size + sub_image_size//2, sub_image_size//2 + 1)\n",
    "                rr -= i*sub_image_size  # Adjust the coordinates to the sub-image's coordinate system\n",
    "                cc -= j*sub_image_size  # Adjust the coordinates to the sub-image's coordinate system\n",
    "                # Clip the indices to the valid range\n",
    "                rr = np.clip(rr, 0, sub_image_size-1)\n",
    "                cc = np.clip(cc, 0, sub_image_size-1)\n",
    "                sub_image = anomaly_images[channel][i*sub_image_size:(i+1)*sub_image_size, j*sub_image_size:(j+1)*sub_image_size]\n",
    "                sub_image[rr, cc] = [255, 0, 0]  # Draw the circle in red on the sub-image\n",
    "\n",
    "    # Plot the images with anomalies\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(30, 30))\n",
    "    axs[0].imshow(anomaly_images['DAPI'], cmap='gray')\n",
    "    axs[0].set_title('DAPI with anomalies')\n",
    "    axs[1].imshow(anomaly_images['CY5'], cmap='gray')\n",
    "    axs[1].set_title('CY5 with anomalies')\n",
    "    plt.show()\n",
    "\n",
    "# Create sliders to select the anomaly score thresholds\n",
    "slider_threshold_dapi = widgets.FloatSlider(min=-1.0, max=1.0, step=0.01, value=-0.1, description='Threshold DAPI:')\n",
    "slider_threshold_cy5 = widgets.FloatSlider(min=-1.0, max=1.0, step=0.01, value=-0.2, description='Threshold CY5:')\n",
    "\n",
    "# Create interactive widgets to plot the anomalies\n",
    "widgets.interact(plot_anomalies, threshold_dapi=slider_threshold_dapi, threshold_cy5=slider_threshold_cy5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ba703-0e5e-49a6-b0b2-22949650e474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
